{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style=\"float: right\" src=\"img/saturn.png\" width=\"300\" />\n",
    "\n",
    "# Machine Learning on Big Data with Dask\n",
    "\n",
    "## Introduction to Dask\n",
    "<img src=\"https://docs.dask.org/en/latest/_images/dask_horizontal_no_pad.svg\" width=\"300\" alt=\"dask\" />\n",
    "\n",
    "Before we get into too much complexity, let's talk about the essentials of Dask.\n",
    "\n",
    "## What is Dask?\n",
    "\n",
    "Dask is an open-source framework that enables parallelization of Python code. This can be applied to all kinds of Python use cases, not just machine learning. Dask is designed to work well on single-machine setups and on multi-machine clusters. You can use Dask with pandas, NumPy, scikit-learn, and other Python libraries. If you want to learn more about the other areas where Dask can be useful, there's a [great website explaining all of that](https://dask.org/).\n",
    "\n",
    "## Why Parallelize?\n",
    "\n",
    "For machine learning use cases, parallelizing work with Dask can be useful if:\n",
    "\n",
    "- Data sizes exceed memory of a single node\n",
    "- Complex data transformation that is slow on a single node\n",
    "- Complex models that require a lot of resources\n",
    "- Many compute tasks that can execute at the same time (think hyperparameter tuning, ensemble models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Dask cluster\n",
    "\n",
    "The `dask_saturn` package makes the Dask Cluster that we created from Saturn Cloud accessible in our notebook. If the cluster was already created, we would not need to specify any arguments when initializing `SaturnCluster`, but it is a good idea to do so for reproducibility purposes. The arguments to `SaturnCluster` match the fields presented when editing a Dask Cluster from the Saturn Cloud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask_saturn import SaturnCluster\n",
    "from dask.distributed import Client\n",
    "\n",
    "cluster = SaturnCluster(\n",
    "    scheduler_size='medium',\n",
    "    worker_size='xlarge',\n",
    "    n_workers=5,\n",
    "    nthreads=4,\n",
    ")\n",
    "client = Client(cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "To see the options for scheduler and worker sizes, and how they match up to the options presented in Saturn Cloud, run the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask_saturn.core import describe_sizes\n",
    "describe_sizes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "The `Client` object is our \"entry point\" to Dask. Most Dask operations will automatically detect the client and run operations across the cluster, but sometimes its necessary to pass a `client` object when performing more advanced operations. Previewing the `client` object tells us details about the cluster and a link to the Dashboard. Open up the Dashboard now and keep it  visible in a separate window - you'll see it light up when we run Dask operations!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell will block until all workers are available. You can also view cluster status and access the Dashbaord link from the Project page in Saturn Cloud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.wait_for_workers(5)\n",
    "print('Ready to go!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lazy evaluation - dask.delayed\n",
    "\n",
    "Delaying a task with Dask can queue up a set of transformations or calculations so that it's ready to run later, in parallel. This is what's known as \"lazy\" evaluation - it won't evaluate the requested computations until explicitly told to. This differs from other kinds of functions, which compute instantly upon being called. Many very common and handy functions are ported to be native in Dask, which means they will be lazy (delayed computation) without you ever having to even ask. \n",
    "\n",
    "However, sometimes you will have complicated custom code that is written in pandas, scikit-learn, or even base python, that isn't natively available in Dask. Other times, you may just not have the time or energy to refactor your code into Dask, if edits are needed to take advantage of native Dask elements.\n",
    "If this is the case, you can decorate your functions with `@dask.delayed`, which will manually establish that the function should be lazy, and not evaluate until you tell it. You'd tell it with the processes `.compute()` or `.persist()`, described in the next section. We'll use `@dask.delayed` several times in this workshop to make PyTorch tasks easily parallelized.\n",
    "\n",
    "Let's start with a small example. We have a function `multiply()` that multiplies two numbers together. We can call the function to see its result:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiply(x, y):\n",
    "    return x * y\n",
    "\n",
    "multiply(2, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can decorate the function with `@dask.delayed` to indicate that we want to the function to execute lazily on our cluster:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask\n",
    "\n",
    "@dask.delayed\n",
    "def multiply_dask(x, y):\n",
    "    return x * y\n",
    "\n",
    "multiply_dask(2, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is quite different output than calling a normal function. This is because Dask hasn't done anything yet! Call `.compute()` to get the actual result.\n",
    "> Tip: Open up the Dask Dashboard to see the task executing on the cluster!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiply_dask(2, 3).compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can even chain together multiple delayed functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = multiply_dask(2, 3)\n",
    "y = multiply_dask(3, 4)\n",
    "z = x * y\n",
    "z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Get the result of `z`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<<< FILL IN >>>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "z.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Persist vs Compute\n",
    "\n",
    "Lots of new users of Dask find the `.persist()` and `.compute()` processes confusing. This is understandable! But the answer is not as hard as you might think.\n",
    "\n",
    "First, remember when working with a cluster we have several machines working for us. We have our Jupyter instance right here running on one, and then our cluster of worker machines also.\n",
    "\n",
    "If we use `.compute()`, we are asking Dask to take all the computations and adjustments to the data that we have queued up, and run them, and bring it all to the surface here, in Jupyter. That means if it was distributed we want to convert it into a local object here and now. If it's a Dask Dataframe, when we call `.compute()`, we're saying \"Run the transformations we've queued, and convert this into a pandas dataframe immediately.\" If our data is too big to be held in local pandas memory, this can be a disaster! But if it is small, then we might be fine.\n",
    "\n",
    "If we use `.persist()`, we are asking Dask to take all the computations and adjustments to the data that we have queued up, and run them, but then the object is going to remain distributed and will live on the cluster, not on the Jupyter instance. So when we do this with a Dask Dataframe, we are telling our cluster \"Run the transformations we've queued, and leave this as a distributed Dask Dataframe.\"\n",
    "\n",
    "So, if you want to process all the delayed tasks you've applied to a Dask object, either of these methods will do it. **The difference is where your object will live at the end.**\n",
    "\n",
    "We will use `persist()` in later examples when working with Dask DataFrames."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
